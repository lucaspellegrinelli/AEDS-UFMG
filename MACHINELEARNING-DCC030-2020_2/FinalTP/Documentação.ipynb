{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Obtenção do dataset\n",
    "\n",
    "## 2.1. Imagens dos pokemons\n",
    "\n",
    "No inicio do desenvolvimento do projeto, o maior problema enfrentado foi justamente encontrar imagens de cada um dos pokemons. Isso é um problema visto que para treinar o modelo, precisaríamos de bem mais que uma imagem de cada um deles, e encontrar um banco de dados com essas imagens diretamente não foi possível.\n",
    "\n",
    "Surgiu então a ideia de utilizar as imagens utilizadas como arte das cartas do jogo de carta tematizado no universo de pokemon. Isso foi conseguido por meio de um web scraper desenvolvido para percorrer as páginas do website https://pkmncards.com/, que é um site onde jogadores do jogo de carta podem visitar para olhar informações sobre cada uma das cartas do jogo.\n",
    "\n",
    "Cada uma dessas cartas possuí uma arte diferente, mesmo sendo do mesmo pokemon. Isso implica que caso pudessemos utilizar essas artes para treinar o modelo, teríamos uma quantidade muito maior de dados de entrada do que usando apenas uma imagem para cada um dos pokemons.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src='https://i.imgur.com/6BeJaIB.jpg'/ style=\"height: 250px;\"></td>\n",
    "<td><img src='https://i.imgur.com/aDqF2nn.jpg'/ style=\"height: 250px;\"></td>\n",
    "<td><img src='https://i.imgur.com/G1xLJcc.jpg'/ style=\"height: 250px;\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Pode ser observado também, que em geral, a imagem do pokemon fica em uma posição bem específica em cada uma das cartas. Isso nos possibilita obter a imagem dos pokemons de forma fácil. O resultado é como nas imagens a seguir.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src='https://i.imgur.com/ainlu5d.jpg'/ style=\"height: 150px;\"></td>\n",
    "<td><img src='https://i.imgur.com/pWPpPle.jpg'/ style=\"height: 150px;\"></td>\n",
    "<td><img src='https://i.imgur.com/FD5l5v1.jpg'/ style=\"height: 150px;\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Porém existem cartas especiais chamadas de \"full cover\", onde a arte do pokemon ocupa todo o espaço da carta. Como não havia um jeito prático de separar essas cartas das cartas comuns, elas ficaram como um ruído no dataset. Esse ruído não é tão ruim já que geralmente em cartas full cover, a \"face\" do pokemon fica no lugar onde a imagem fica em cartas comum, então a imagem gerada após cortar a região da carta ainda faz algum sentido. Alguns exemplos de cartas full cover cortadas vem a seguir.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src='https://i.imgur.com/Y7AiT7L.jpg'/ style=\"height: 150px;\"></td>\n",
    "<td><img src='https://i.imgur.com/umSI8lZ.jpg'/ style=\"height: 150px;\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Ao final, foram obtidas 10455 imagens de 807 pokemons diferentes.\n",
    "\n",
    "## 2.2. Tipos de cada pokemon\n",
    "\n",
    "Os tipos de pokemon foram obtidos a partir de um CSV disponibilizado pelo projeto no github do usuário Veekun. http://github.com/veekun/pokedex/\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src='https://i.imgur.com/JZkB2F5.jpg'/ style=\"height: 250px;\"></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Esse CSV tem, em cada linha, o ID de um pokemon, o ID de um dos seus tipo e uma variável ```slot``` que indica se aquele tipo é o primeiro ou o segundo tipo do pokemon em questão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementação de funções auxiliares\n",
    "\n",
    "O método abaixo serve para auxiliar posteriormente a plotar métricas do modelo treinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def pretty_plot(all_metrics, metric_info, texts, x_tick_labels):\n",
    "    stats = []\n",
    "    for m in metric_info:\n",
    "        stats.append(np.array([s[m[\"name\"]] for s in all_metrics]))\n",
    "        \n",
    "    xs = np.linspace(0, stats[0].shape[0] - 1, stats[0].shape[0])\n",
    "    \n",
    "    errorbar_style = {\"linestyle\":\"--\", \"linewidth\":1, \"markeredgewidth\":2, \"elinewidth\":2, \"capsize\":3, \"marker\": \"^\"}\n",
    "    plot_style = {\"linestyle\":\"--\", \"linewidth\":1, \"markeredgewidth\":2, \"marker\": \"^\"}\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "    ax = [plt.subplot(2, 1, i + 1) for i in range(len(metric_info))]\n",
    "    \n",
    "    colors = [\"#e74c3c\", \"#2ecc71\"]\n",
    "    \n",
    "    for i, m in enumerate(metric_info):\n",
    "        curr_color = colors[i % len(colors)]\n",
    "        if m[\"type\"] == \"error\":               \n",
    "            ax[i].errorbar(xs, stats[i].mean(axis=1), stats[i].std(axis=1), **errorbar_style, color=curr_color)\n",
    "        elif m[\"type\"] == \"simple\":\n",
    "            if m[\"format\"] == \"mean\":\n",
    "                ax[i].plot(xs, stats[i].mean(axis=1), **plot_style, color=curr_color)\n",
    "            elif m[\"format\"] == \"single\":\n",
    "                ax[i].plot(xs, stats[i], **plot_style, color=curr_color)\n",
    "             \n",
    "        ax[i].xaxis.set_ticks(xs)\n",
    "        ax[i].set_xticklabels(x_tick_labels)\n",
    "        ax[i].set_title(texts[i][\"title\"])\n",
    "        ax[i].set_xlabel(\"Fold\")\n",
    "        ax[i].set_ylabel(texts[i][\"ylabel\"])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Implementação do algoritmo de aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Definição dos tipos\n",
    "\n",
    "Inicialmente, iremos definir uma das constantes mais importantes do problema: os tipos de Pokemon existentes.\n",
    "\n",
    "Atualmente, existem 18 tipos Pokemon:\n",
    " - Normal, Lutador, Voador, Venenoso, Terra, Pedra, Inseto, Fantasma, Metálico, Fogo, Água, Planta, Elétrico, Psíquico, Gelo, Dragrão, Noturno e Fada\n",
    " \n",
    "<img src=\"https://i.imgur.com/sggUsfN.png\" style=\"height: 200px;\">\n",
    " \n",
    "Na célula abaixo é definido uma lista com esses tipos de modo a indexa-los para uso futuro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_label = [\n",
    "    \"normal\", \"fighting\", \"flying\", \"poison\", \"ground\", \"rock\",\n",
    "    \"bug\", \"ghost\", \"steel\", \"fire\", \"water\", \"grass\", \"electric\",\n",
    "    \"psychic\", \"ice\", \"dragon\", \"dark\", \"fairy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Gerenciando o dataset\n",
    "\n",
    "Para gerenciar o dataset, foi criada uma classe ```DatasetHandler``` que tem como entrada o caminho para a pasta onde todas as imagens estão, o caminho para o arquivo CSV contendo as informações de qual pokemon tem quais tipos e o algoritmo de data augmentation que será definido posteriormente.\n",
    "\n",
    "Essa classe tem 3 métodos:\n",
    " - ```pokemons_to_labels```\n",
    " \n",
    "   - Cada Pokemon pode ter 1 ou 2 tipos associados a ele. Para obter essas informações foi obtido um arquivo CSV que contém, em cada linha, o ID de um Pokemon e o ID de um dos seus tipos. Esse ID do tipo segue a ordem de tipos definido pela variável ```types_label``` definida anteriormente.\n",
    "\n",
    "     Com esse CSV aberto, será criado um dicionário ```types_by_pokemon``` que associa o ID de um pokemon a um N-Hot-Encoding de seu tipo (ou seja, uma lista com 18 posições onde uma posição tem o valor ```1``` caso o índice daquela posição corresponde a um tipo que aquele pokemon tem e ```0``` caso contrário).\n",
    "\n",
    "     Então, a posição do dicionário associada ao pokemon \"Bulbassauro\" deverá ser ```[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]``` visto que seus tipos são Planta e Venenoso, correspondendo ás posições 3 e 11 da lista.\n",
    "\n",
    "\n",
    " - ```create_data_generators``` que é responsável por, a partir de um DataFrame contendo o caminho para uma das imagens e os valores\n",
    " \n",
    "   - Esse método cria objetos ```DataGenerator``` do Keras a partir de um DataFrame contendo o caminho para as imagens do dataset e, para cada uma delas, 18 valores correspondendo ao N-Hot-Encoding criado pela função ```pokemons_to_labels```. Esses ```DataGenerators``` servirão de uso quando utilizaremos alguns métodos de transformação nas imagens obtidas.\n",
    "   \n",
    "   \n",
    " - ```create_dataset``` que é resoponsável por criar uma DataFrame\n",
    "   - Esse método é quem junta os outros dois e retorna um dataset final. Ele cria o DataFrame que será utilizado pelo método ```create_data_generators``` a partir dos resultados do método ```pokemons_to_labels``` e ao fim retorna os ```DataGenerators``` de treino e validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DatasetHandler:\n",
    "  def __init__(self, image_paths, types_csv, datagen, fold=None):\n",
    "    # Load and shuffle image paths\n",
    "    self.image_paths = list(paths.list_images(image_paths))\n",
    "    \n",
    "    self.fold = fold\n",
    "\n",
    "    # Load types csv\n",
    "    self.types = pd.read_csv(types_csv)\n",
    "\n",
    "    # ImageGenerator options\n",
    "    self.datagen = datagen\n",
    "\n",
    "  # With the pokemon pokedex id as input, this function returns in an\n",
    "  # one-hot-encoding form their encoded types\n",
    "  def pokemons_to_labels(self):\n",
    "    types_by_pokemon = {}\n",
    "    min_id = self.types.pokemon_id.min()\n",
    "    max_id = self.types[self.types.pokemon_id <= 1000].pokemon_id.max()\n",
    "\n",
    "    for i in range(min_id, max_id + 1):\n",
    "      types_id = self.types[self.types.pokemon_id == i][\"type_id\"].to_numpy()\n",
    "      one_hot = [0] * len(types_label)\n",
    "      for t_id in types_id:\n",
    "        one_hot[t_id - 1] = 1\n",
    "\n",
    "      types_by_pokemon[i] = one_hot\n",
    "\n",
    "    return types_by_pokemon\n",
    "\n",
    "  # Creates a DataFrame with all pokemon image paths and their correspondent\n",
    "  # one-hot-encoded types.\n",
    "  def create_dataset(self, verbose=False, seed=None):\n",
    "    types_by_pokemon = self.pokemons_to_labels()\n",
    "\n",
    "    paths, labels = [], []\n",
    "    for path in self.image_paths:\n",
    "      pkm_id = int(path.split(\"/\")[-1].split(\"-\")[0])\n",
    "      labels.append(types_by_pokemon[pkm_id])\n",
    "      paths.append(path)\n",
    "\n",
    "    dataset_df = pd.DataFrame(labels, columns=types_label)\n",
    "    dataset_df[\"path\"] = paths\n",
    "\n",
    "    train_gen, val_gen = self.create_data_generators(dataset_df, seed)\n",
    "    return dataset_df, train_gen, val_gen\n",
    "\n",
    "  # Creates the data generators from the dataframe inputted\n",
    "  def create_data_generators(self, df_dataset, seed=None):\n",
    "    dataset_cols = [\"path\"] + types_label\n",
    "\n",
    "    for col in dataset_cols[1:]:\n",
    "      df_dataset[col] = pd.to_numeric(df_dataset[col])\n",
    "\n",
    "    if self.fold is None:\n",
    "        train_generator = self.datagen.flow_from_dataframe(\n",
    "          dataframe=df_dataset,\n",
    "          x_col=dataset_cols[0],\n",
    "          y_col=dataset_cols[1:],\n",
    "          subset=\"training\",\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          class_mode=\"raw\",\n",
    "          target_size=(100, 137),\n",
    "          seed=seed\n",
    "        )\n",
    "\n",
    "        valid_generator = self.datagen.flow_from_dataframe(\n",
    "          dataframe=df_dataset,\n",
    "          x_col=dataset_cols[0],\n",
    "          y_col=dataset_cols[1:],\n",
    "          subset=\"validation\",\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          class_mode=\"raw\",\n",
    "          target_size=(100, 137),\n",
    "          seed=seed\n",
    "        )\n",
    "    else:\n",
    "        fold_size = len(df_dataset) / self.fold[1]\n",
    "        fold_init = int(self.fold[0] * fold_size)\n",
    "        fold_end = int((self.fold[0] + 1) * fold_size)\n",
    "        \n",
    "        train_fold_i = list(range(fold_init)) + list(range(fold_end, len(df_dataset)))\n",
    "        test_fold_i = list(range(fold_init, fold_end))\n",
    "        train_df = df_dataset.iloc[train_fold_i]\n",
    "        test_df = df_dataset.iloc[test_fold_i]\n",
    "        \n",
    "        train_generator = self.datagen.flow_from_dataframe(\n",
    "          dataframe=train_df,\n",
    "          x_col=dataset_cols[0],\n",
    "          y_col=dataset_cols[1:],\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          class_mode=\"raw\",\n",
    "          target_size=(100, 137),\n",
    "          seed=seed\n",
    "        )\n",
    "\n",
    "        valid_generator = self.datagen.flow_from_dataframe(\n",
    "          dataframe=test_df,\n",
    "          x_col=dataset_cols[0],\n",
    "          y_col=dataset_cols[1:],\n",
    "          batch_size=32,\n",
    "          shuffle=True,\n",
    "          class_mode=\"raw\",\n",
    "          target_size=(100, 137),\n",
    "          seed=seed\n",
    "        )\n",
    "\n",
    "    return train_generator, valid_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Definição do algoritmo de Data-Augmentation\n",
    "\n",
    "Para evitar overfit, será utilizada a classe ```ImageDataGenerator``` provida pelo Keras que, a partir dos ```DataGenerators``` gerados previamente, ele fará algumas pequenas modificações nas imagens a medida que o modelo é treinado. Essas pequenas modificações incluem rotacionar as imagens, dar (ou tirar) zoom e espelha-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    validation_split=0.2,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    "    rotation_range=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Definição do modelo que será utilizado\n",
    "\n",
    "Para essa tarefa, como é baseada em encontrar features em imagens, naturalmente as Redes Neurais Convolucionais se tornam uma alternativa interessante, e assim foi escolhida a arquitetura que será utilizada para resolver esse problema.\n",
    "\n",
    "A entrada para essa CNN são as imagens dos pokemons (usandos os 3 canais de cores) e como saída esperamos o N-Hot-Encoding que nos dirá o tipo daquele pokemon.\n",
    "\n",
    "O modelo utilizado será o ```SqueezeNet``` devido a sua simplicidade e leveza, fazendo o treinamento da rede menos custoso e mais rápido em troca de sua capacidade. A implementação desse modelo foi tirada do github do usuário ```DT42``` (https://github.com/DT42/squeezenet_demo/) e modificada para que ela funcionasse como um modelo multi-label para a predição de até 2 tipos de um pokemon.\n",
    "\n",
    "Para o otimizador, foi escolhido o ```adam``` que é um otimizador bom para CNNs em diversos problemas. Já para a função de perda foi escolhida a ```binary_crossentropy``` visto que ela da suporte a classificação binária múltipla (mais de uma opção marcada como 1 possível)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from model import SqueezeNet\n",
    "\n",
    "def create_model():\n",
    "    model = SqueezeNet(nb_classes=18, inputs=(100, 137, 3))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Crossvalidation com 5 folds\n",
    "\n",
    "Para validar o experimento, foi feito um crossvalidation com 5 folds no dataset. Em cada iteração, $\\frac{1}{5}$ dos dados diferentes das outras iterações foram utilizadas como validação enquanto as os outros $\\frac{4}{5}$ dos dados foram utilizados como treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"dataset/images/\"\n",
    "types_csv_path = \"dataset/pokemon_types.csv\"\n",
    "\n",
    "fold_histories = []\n",
    "\n",
    "for fold in range(5):   \n",
    "    ds_handler = DatasetHandler(image_path, types_csv_path, data_gen, (fold, 5))\n",
    "    df_dataset, train_generator, valid_generator = ds_handler.create_dataset(verbose=False, seed=42)\n",
    "    \n",
    "    model = create_model()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=15)]\n",
    "    \n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "        validation_data=valid_generator,\n",
    "        validation_steps=valid_generator.n // valid_generator.batch_size,\n",
    "        epochs=500,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    fold_histories.append(history)\n",
    "    \n",
    "all_metrics = []\n",
    "for h in fold_histories:\n",
    "    all_metrics.append(h.history)\n",
    "\n",
    "pretty_plot(all_metrics, [\n",
    "    { \"name\": \"val_loss\", \"type\": \"simple\", \"format\": \"mean\" }\n",
    "], [\n",
    "    { \"title\": \"Validation Binary Crossentropy Loss over 5 folds\", \"ylabel\": \"Validation Binary Crossentropy Loss\" },\n",
    "], list(range(1, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os erros de validação obtidos durante o 5-fold podem ser observados na figura abaixo.\n",
    "\n",
    "<img src=\"https://i.imgur.com/VfLhi4Z.png\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6. Otimização do modelo final\n",
    "\n",
    "Foram treinados diversos modelos, variando hiperparâmetros como ```batch_size``` e parâmetros do data augmentation. Esses experimentos não só testaram combinações diferentes de valores desses hiperparâmetros, mas também deram mais oportunidades para a rede neural não cair em um mínimo local muito cedo durante o treinamento.\n",
    "\n",
    "Para essa otimização de parâmetros foi utilizado o Grid Search, variando o batch size nos valores ```[8, 16, 32, 64]```, o máximo de zoom das imagens entre ```[0.0, 0.15, 0.3, 0.45]``` e se o algoritmo pode ou não espelhar as imagens. Os melhores resultados foram obtidos com os parâmetros\n",
    "\n",
    " - ```batch_size = 32```\n",
    " - ```zoom_range = 0.15```\n",
    " - ```horizontal_flip = True```\n",
    " \n",
    "Um passo futuro para o desenvolvimento desse projeto seria incluir mais hiperparâmetros para serem otimizados, porém, devido ao tempo que experimentos tomam aumentarem exponencialmente com a inclusão de mais hiperparâmetros, os resultados apresentados aqui conterão apenas os citados previamente.\n",
    "\n",
    "### Modelo Final\n",
    "\n",
    "O modelo final que atingiu o menor ```validation loss``` conseguiu um valor de ```val_loss = 0.2503```. Exemplos dos resultados obtidos por meio da aplicação dele nos dados de validação podem ser observados a seguir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualização de resultados\n",
    "\n",
    "A célula abaixo pega os dados de validação e executa o modelo sobre eles e retorna uma lista de probabilidades para cada um dos tipos que representa a confiança do modelo de que aquele pokemon da imagem é daquele tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "NUM_EXAMPLES = 16\n",
    "\n",
    "ds_handler = DatasetHandler(image_path, types_csv_path, data_gen)\n",
    "_, _, validation_generator = ds_handler.create_dataset(verbose=False, seed=42)\n",
    "\n",
    "model = load_model(\"models/pkm_model-0.2503.hdf5\")\n",
    "\n",
    "example_count = 0\n",
    "while example_count < NUM_EXAMPLES:\n",
    "  x_batch, y_batch = validation_generator.next()\n",
    "  for i, image in enumerate(x_batch):\n",
    "    example_count += 1\n",
    "    if example_count > NUM_EXAMPLES:\n",
    "      break\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0))[0]\n",
    "    prediction_labeled = sorted(list(zip(prediction, types_label)), reverse=True)\n",
    "    for prob, name in prediction_labeled[:6]:\n",
    "      print(name, prob * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Análise de resultados\n",
    "\n",
    "Nessa seção mostrarei alguns exemplos onde o modelo acertou, errou e possíveis explicações.\n",
    "\n",
    "Na tabela a seguir, na primeira coluna temos uma imagem que mostra o nome do pokemon em questão, uma imagem dele os tipos corretos dele nos jogos. Na coluna do meio temos a imagem dada ao modelo e embaixo da imagem temos os 6 tipos que o modelo tem mais confiança. Na última coluna temos comentários sobre a predição.\n",
    "\n",
    "|            Pokemon Original          |     Imagem de entrada / Predições    |       Comentários      |\n",
    "|:------------------------------------:|:------------------------------------:|:------------------------------------:|\n",
    "| ![](https://i.imgur.com/eh1yR1G.png) | ![](https://i.imgur.com/QL0qlz0.png) | O pokemon está com um tom de azul e textura que lembra água |\n",
    "| ![](https://i.imgur.com/LLiF9Y0.png) | ![](https://i.imgur.com/WglhWVB.png) | Predizeu corretamente. Porém as cores ao redor do pokemon influenciaram bastante as previsões seguintes a previsão correta |\n",
    "| ![](https://i.imgur.com/YOFYEqi.png) | ![](https://i.imgur.com/kSiSLaz.png) | Muito verde geralmente indica um pokemon de planta ou inseto |\n",
    "| ![](https://i.imgur.com/GxmeOLI.png) | ![](https://i.imgur.com/RAQDUC8.png) | Acertou, mas é possível perceber que como amarelo geralmente indicia um pokemon elétrico, a predição de \"elétrico\" ficou em segundo lugar). |\n",
    "| ![](https://i.imgur.com/vBrk7p3.png) | ![](https://i.imgur.com/1ohSBbF.png) | Roxo geralmente indica um pokemon venenoso ou psíquico, mas nesse exemplo o modelo conseguiu distinguir que o pokemon não é psíquico |\n",
    "| ![](https://i.imgur.com/NFTvT1k.png) | ![](https://i.imgur.com/46V6N48.png) | Não conseguiu prever o tipo elétrico, provavelmente pela ausência da cor amarela |\n",
    "| ![](https://i.imgur.com/tTEokHj.png) | ![](https://i.imgur.com/Mi0YDYj.png) | Envolta do pokemon tem muitos tons de cinza, cores que geralmente estão presentes em pokemons normais ou voadores. |\n",
    "| ![](https://i.imgur.com/NTjgkGo.png) | ![](https://i.imgur.com/B3JYZI9.png) | Rosa geralmente indica pokemons fada. A predição de \"planta\" está alta também devido à floresta |\n",
    "| ![](https://i.imgur.com/wuzrsYS.png) | ![](https://i.imgur.com/SZkvZY9.png) | Claramente o modelo chutou \"água\" e \"elétrico\" por conta das cores predominantes da imagem (azul e amarelo). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Comentários finais\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
